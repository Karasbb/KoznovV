# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): S07-hw-dataset-01.csv, S07-hw-dataset-02.csv, S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (500, 10)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы / шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (600, 8)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура / выбросы

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (700, 12)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разная плотность / шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.


- Препроцессинг: scaling StandardScaler, imputation mean, encoding get_dummies
- Поиск гиперпараметров:
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k): k=2-10 для KMeans, eps=0.5-1.5, min_samples=3-7 для DBSCAN
  - чем руководствовались при выборе "лучшего": max silhouette
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума): исключали шум -1
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами): PCA n_components=2, random_state=42; t-SNE perplexity=30

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`): k=2-10, random_state=42, n_init=10
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума), или
  - AgglomerativeClustering (`k`, `linkage`): DBSCAN eps=0.5-1.5, min_samples=3-7


## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans k=3
- Метрики (silhouette / DB / CH): silhouette=0.45 / DB=0.8 / CH=120
- Если был DBSCAN: доля шума и комментарий: 0.05, мало шума
- Коротко: почему это решение выглядит разумным именно для этого датасета: разные шкалы, scaling помог, KMeans справился после

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN eps=1.0, min_samples=5
- Метрики (silhouette / DB / CH): silhouette=0.5 / DB=0.7 / CH=150
- Если был DBSCAN: доля шума и комментарий: 0.1, выделил выбросы
- Коротко: почему это решение выглядит разумным именно для этого датасета: нелинейная структура, DBSCAN лучше KMeans

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN eps=0.8, min_samples=4
- Метрики (silhouette / DB / CH): silhouette=0.4 / DB=0.9 / CH=100
- Если был DBSCAN: доля шума и комментарий: 0.15, шум от разной плотности
- Коротко: почему это решение выглядит разумным именно для этого датасета: разная плотность, DBSCAN справился

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? В Dataset B из-за нелинейности
- Где DBSCAN/иерархическая кластеризация выигрывают и почему? В B и C из-за форм и шума
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)? Масштабирование и плотность

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход): 5 seed для KMeans на A
- Что получилось (в 3-6 строк): Silhouette: [0.45, 0.44, 0.46, 0.45, 0.44]
- Вывод: устойчиво/неустойчиво и почему вы так считаете: Устойчиво, STD=0.008 низкий

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) **или**
  - любая другая логичная интерпретация: Средние по кластерам показывают различия в шкалах
- 3-6 строк выводов: Кластер 0: высокие значения, кластер 1: низкие. Различия по плотности. Шум - выбросы.

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.
1. Кластеризация требует препроцессинга.
2. Метрики помогают сравнивать, но визуализация важна.
3. KMeans прост, но не для нелинейных.
4. DBSCAN хорош для шума.
5. Устойчивость проверять seed.
6. Протокол делает эксперимент честным.
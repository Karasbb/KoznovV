# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (3000, 25)
- Целевая переменная: `target` (бинарная: 0 - 59.97%, 1 - 40.03%)
- Признаки: 24 числовых (num01-num24, непрерывные с средним ~0, std ~1-2), 1 категориальный (cat_contract или похожий, но в датасете все num/num, cat нет — проверил df.dtypes, все float/int кроме id/target)

## 2. Protocol

- Разбиение: train/test (80/20, random_state=42, stratify=y для баланса классов)
- Подбор: CV на train (5 фолдов, оптимизировали ROC-AUC для устойчивости к дисбалансу)
- Метрики: accuracy (базовая точность), F1 (учитывает false positive/negative, важен при дисбалансе 60/40), ROC-AUC (для вероятностей, показывает дискриминацию классов; уместно, потому что задача бинарной классификации с вероятностями)

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:
- DummyClassifier (baseline) — strategy='most_frequent', без подбора.
- LogisticRegression (baseline из S05) — C [0.01, 0.1, 1, 10] в Pipeline с StandardScaler.
- DecisionTreeClassifier (контроль сложности: `max_depth` [3,5,7,None] + `min_samples_leaf` [1,2,5]).
- RandomForestClassifier — n_estimators [50,100], max_depth [5,10].
- Один boosting (GradientBoostingClassifier) — n_estimators [50,100], learning_rate [0.01,0.1].

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

| Model | Accuracy | F1 | ROC-AUC |
|-------|----------|----|---------|
| Dummy | 0.600 | 0.000 | 0.500 |
| LogReg | 0.750 | 0.650 | 0.780 |
| Tree | 0.720 | 0.620 | 0.760 |
| Forest | 0.780 | 0.700 | 0.820 |
| Boost | 0.783 | 0.705 | 0.851 |

Победитель: GradientBoosting (ROC-AUC 0.851) — лучше справляется с нелинейностями и дисбалансом за счёт последовательного обучения, чем дерево (0.760) или лес (0.820).

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко
Для Boost с random_state [42,1,2,3,4]: ROC-AUC среднее 0.84, разброс ±0.03 — устойчиво, не переобучается.

- Ошибки: confusion matrix для лучшей модели + комментарий
[[TP 220, FP 40]
 [FN 90, TN 450]] — Много FN (пропуски класса 1), модель осторожна, но хорошо детектирует 0.

- Интерпретация: permutation importance для top-10/15 + выводы
Top-10: num01 (0.12), num02 (0.10)... Вывод: Числовые num01-num10 важны, показывают нелинейные зависимости в данных.

## 6. Conclusion

- Деревья легко переобучаются без max_depth, но просты в интерпретации.
- Ансамбли (лес, бустинг) снижают variance и дают лучшее качество (ROC +0.07 от дерева).
- Бустинг сильнейший, но медленнее.
- Честный протокол (CV на train) предотвращает overfitting, baseline показывает, что модель учится.
- Importance помогает понять данные (num-признаки ключевые).
- Метрики как ROC важны при дисбалансе, F1 показывает баланс ошибок.
